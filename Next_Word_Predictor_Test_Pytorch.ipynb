{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Import The Libraries"
      ],
      "metadata": {
        "id": "u7mKITioTeQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "ko3YUYxJThSA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load The Tokenizer And The Vocabulary"
      ],
      "metadata": {
        "id": "WczDTdpMTpZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tokenizer(vocab_path):\n",
        "    with open(vocab_path, 'r') as f:\n",
        "        word_index = json.load(f)\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.word_index = word_index\n",
        "    return tokenizer\n",
        "\n",
        "def load_model(model_path):\n",
        "  model=torch.load(model_path)\n",
        "  model.eval()  #Set the model in the evaluation mode\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "dZYZuMDpTh9s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function To Remove Punctuations"
      ],
      "metadata": {
        "id": "irfMS2dBUIDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    return re.sub(r'[^\\w\\s]', '', text).strip()"
      ],
      "metadata": {
        "id": "Qlqidb2rUOZY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Definition"
      ],
      "metadata": {
        "id": "_ErOB40leQG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Next_Word_Predictor(nn.Module):\n",
        "    def __init__(self, num_classes, embedding_dim=100, lstm_units=150,dropout_prob=0.5):\n",
        "        super(Next_Word_Predictor, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_classes, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, lstm_units, batch_first=True, bidirectional=True,dropout=dropout_prob)\n",
        "        self.fc = nn.Linear(lstm_units * 2, num_classes)\n",
        "        self.dropout=nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zl_7cl9eeTDr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Method To Predict The Next Word"
      ],
      "metadata": {
        "id": "vK_U_YDNUbNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict next words\n",
        "def predict_next_words(text, tokenizer, model, max_sequence_length, top_k=5):\n",
        "    # Preprocess the text\n",
        "    preprocessed_text = preprocess_text(text)\n",
        "\n",
        "    # Convert text to sequence of indices\n",
        "    sequence = tokenizer.texts_to_sequences([preprocessed_text])[0]\n",
        "\n",
        "    if not sequence:\n",
        "        return [\"No prediction available\"]\n",
        "\n",
        "    # Pad the sequence\n",
        "    sequence = pad_sequences([sequence], maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "    # Convert to tensor\n",
        "    input_sequence = torch.tensor(sequence, dtype=torch.long)\n",
        "\n",
        "    # Make the prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(input_sequence)\n",
        "\n",
        "    # Get the top k predicted words\n",
        "    top_k_indices = torch.topk(output, top_k).indices.squeeze().tolist()\n",
        "    top_k_probabilities = torch.softmax(output, dim=1).squeeze().tolist()\n",
        "\n",
        "    # Reverse lookup for the predicted words\n",
        "    index_word = {index: word for word, index in tokenizer.word_index.items()}\n",
        "    predictions = [index_word.get(idx, \"Unknown\") for idx in top_k_indices]\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "p7tL8Nw-Uet_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing"
      ],
      "metadata": {
        "id": "CtE7gaOrUoUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer and model\n",
        "tokenizer = load_tokenizer('/content/vocabulary.json')\n",
        "model = load_model('/content/next_word_predictor.pth')\n",
        "\n",
        "# Max Sequence Length To Exact Value That Was Used During Training\n",
        "max_sequence_length = 19\n",
        "\n",
        "# Example usage\n",
        "#input_text = \"The quick brown\"\n",
        "#predicted_words = predict_next_words(input_text, tokenizer, model, max_sequence_length, top_k=5)\n",
        "#print(f\"Predicted next words for '{input_text}': {predicted_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ittSUGIEUvB5",
        "outputId": "168b67b0-6cfc-4ab7-d5a9-2d4608c7b757"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-c2ce57867c83>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model=torch.load(model_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Predictor Function"
      ],
      "metadata": {
        "id": "rnuorf_dWw_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Predict_Next(text):\n",
        "  # Max Sequence Length To Exact Value That Was Used During Training\n",
        "  max_sequence_length = 17\n",
        "  return predict_next_words(text, tokenizer, model, max_sequence_length, top_k=5)"
      ],
      "metadata": {
        "id": "yaO-WzjdW1uY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing Loop"
      ],
      "metadata": {
        "id": "PQNVAE_KXGtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    text = input(\"Enter some text for next word prediction or press 5 to terminate: \")\n",
        "\n",
        "    # Termination Condition\n",
        "    if text.strip() == '5':\n",
        "        print(\"Terminating the program.\")\n",
        "        break\n",
        "\n",
        "    #Invalid Entry Check\n",
        "    try:\n",
        "        # Try to convert input to integer to check if it's '5'\n",
        "        num = int(text.strip())\n",
        "        if num != 5:\n",
        "            print(\"Invalid entry, please enter some valid inputs.\")\n",
        "            continue\n",
        "    except ValueError:\n",
        "\n",
        "        # Prediction\n",
        "        if text.strip():\n",
        "            predicted_words = Predict_Next(text.strip())\n",
        "            print(f\"These are the predicted next words: {predicted_words}\")\n",
        "        else:\n",
        "            print(\"Empty input detected. Please enter some text.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff22Val2XGeu",
        "outputId": "e84b6a38-f15e-4a82-f078-4d0875849d79"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter some text for next word prediction or press 5 to terminate: I am in\n",
            "These are the predicted next words: ['ur', 'the', 'their', 'sorrow', 'those']\n",
            "Enter some text for next word prediction or press 5 to terminate: I am in the\n",
            "These are the predicted next words: ['language', 'beginning', 'generations', 'cloud', 'chaldees']\n",
            "Enter some text for next word prediction or press 5 to terminate: I am in the generations\n",
            "These are the predicted next words: ['of', 'god', 'from', 'day', 'and']\n",
            "Enter some text for next word prediction or press 5 to terminate: I am in the generations of\n",
            "These are the predicted next words: ['terah', 'haran', 'japheth', 'renown', 'shinar']\n",
            "Enter some text for next word prediction or press 5 to terminate: I am in the generations of japheth\n",
            "These are the predicted next words: ['from', 'after', 'took', 'the', 'two']\n",
            "Enter some text for next word prediction or press 5 to terminate: I am in the generations of japheth after\n",
            "These are the predicted next words: ['their', 'he', 'his', 'two', 'the']\n",
            "Enter some text for next word prediction or press 5 to terminate: 5\n",
            "Terminating the program.\n"
          ]
        }
      ]
    }
  ]
}